## 1. 기본 개념

### 1.1 가상 메모리란?
- **프로세스마다 독립된 메모리 공간**을 제공하는 기법입니다.  
- OS가 ‘가상 주소 → 물리 주소’ 매핑 테이블을 관리해, 프로세스는 자신만의 연속적인 메모리 공간을 갖는 것처럼 동작합니다.

### 1.2 페이지(Page) vs 프레임(Frame)
- **가상 페이지(Virtual Page)**  
  프로세스가 보는 4KB(예시) 단위의 메모리 블록  
- **물리 프레임(Physical Frame)**  
  실제 RAM에서 관리되는 동일 크기의 블록  
- 페이지 하나가 프레임 하나에 매핑되어 메모리 접근이 이루어집니다.

### 1.3 페이지 테이블(Page Table)
- **역할**  
  가상 주소(페이지 번호 + 오프셋) → 물리 주소(프레임 번호 + 오프셋) 변환  
- **구조**  
  - 프로세스마다 독립적인 1차원 배열(또는 다단계 트리)  
  - 각 엔트리(Entry)에 ‘프레임 번호 + 상태 비트(유효/스왑 여부 등)’ 저장

### 1.4 TLB(Translation Lookaside Buffer)
- **역할**  
  자주 참조되는 페이지 테이블 엔트리를 캐시에 저장  
- **해결하는 문제**  
  페이지 테이블(메모리) 조회 비용을 줄여 **주소 변환 속도**를 대폭 향상

---

## 2. 동작 원리 & 예외 상황

### 2.1 페이지 폴트(Page Fault) 발생 과정
1. CPU → MMU: 가상 주소 접근 요청  
2. MMU: TLB 미스 → 페이지 테이블 조회  
3. 페이지 테이블 엔트리 “유효하지 않음” → 페이지 폴트 인터럽트  
4. OS 커널: 디스크(스왑 영역)에서 해당 페이지 Read  
5. 페이지 테이블 업데이트 → CPU 명령 재시도

### 2.2 스왑(Swap) vs 페이징(Paging)
- **페이징**: 가상 페이지 단위로 메모리 ↔ 디스크 블록 교체  
- **스왑**: 프로세스 전체(또는 큰 단위)를 디스크로 옮기는 방식

### 2.3 단편화(Fragmentation)
- **내부 단편화**: 페이지보다 작은 데이터가 남아버린 공간  
- **외부 단편화**: 가변 크기 할당 후 남은 작은 조각들이 흩어져 있는 상태

### 2.4 페이지 교체 알고리즘 예시
- **LRU(Least Recently Used)**: 가장 오랫동안 참조되지 않은 페이지 교체  
- **FIFO(First In, First Out)**: 먼저 들어온 순서대로 교체  
- **OPT(Optimal)**: 앞으로 가장 오랫동안 사용되지 않을 페이지 (이론적)

---

## 3. JVM & 자바 연계

### 3.1 JVM에서의 가상 메모리 활용
- **힙(Heap)**, **메타스페이스(Metaspace)** 등 주요 영역이 모두 가상 주소 공간 위에 할당  
- OS의 페이징·스왑 기능 덕분에 JVM은 “실제 RAM 용량 이상”으로 힙을 설정할 수 있음

### 3.2 OutOfMemoryError와 가상 메모리
- **가상 메모리 한계**: 설정한 힙 사이즈를 초과하면 더 이상 페이지를 할당 못해 OOM 발생  
- **스왑 과다**: 디스크 I/O가 급증해 GC 지연 → 결국 메모리 부족

### 3.3 힙 vs 스택 매핑
- **스택(Stack)**: 각 쓰레드별 고정 크기 가상 페이지로 할당  
- **힙(Heap)**: 동적 용량으로 필요한 만큼 가상 페이지를 요청/반납하며 관리  

---
## 4. 성능 최적화 및 진단

### 4.1 페이지 폴트가 많은 상황의 영향과 해결책  
- **영향**  
  - 디스크 I/O 급증 → 응답 지연, 시스템 전체 처리율 저하  
  - CPU가 페이지 폴트 처리에 시간 소모 → 애플리케이션 로직 실행 지연  
- **해결책**  
  - **워킹 셋(Working Set) 관리**: 자주 쓰는 데이터·코드의 크기를 파악해 메모리에 상주시킴  
  - **프리페칭(prefetching)**: 다음에 쓸 페이지를 미리 로드  
  - **데이터 지역성 개선**: 배열·버퍼를 연속 메모리로 배치해서 한 번에 접근  
  - **메모리 풀 활용**: 새로운 객체 할당/해제를 줄여 메모리 단편화 완화  

### 4.2 TLB 미스 줄이기 위한 코드·데이터 구조 설계  
- **연속 메모리 접근 패턴**  
  - 배열(Array)이나 구조체 배열(Array of Struct)을 사용해 캐시 라인 단위로 접근  
- **데이터 정렬 및 패딩 최소화**  
  - 자주 함께 쓰는 필드를 인접 배치  
  - 구조체 크기를 캐시 라인(64B) 배수로 맞춰서 불필요한 패딩 제거  
- **루프 최적화**  
  - 이중 루프 순서를 바꿔 메모리 접근 지역성 유지  
  - 블록 분할(Block tiling) 기법으로 한 번에 처리할 데이터 크기 제한  

### 4.3 대규모 메모리 워크로드에서 Huge Page 사용 이유와 효과  
- **이유**  
  - 일반 페이지(4KB) 대비 2MB·1GB 등 더 큰 단위로 매핑 → TLB 엔트리 효율 ↑  
  - 페이지 테이블 크기 감소 → 메모리 사용량 절감  
- **효과**  
  - TLB 미스 감소 → 주소 변환 오버헤드 크게 줄어듦  
  - 대용량 연속 버퍼, 메모리 매핑 파일 등에 유리  

---

## 5. 심화 및 시나리오

### 5.1 다단계 페이지 테이블(Multi-level Page Table)의 장단점  
- **장점**  
  - 전체 페이지 테이블을 한 번에 메모리에 올리지 않아도 됨 → 메모리 절약  
  - 64비트처럼 넓은 가상 주소 공간 지원  
- **단점**  
  - 변환 단계(레벨)마다 메모리 접근 필요 → TLB 미스 시 지연 증가  
  - 구현 복잡도 상승  

### 5.2 Copy-on-Write(COW) 메커니즘 동작  
1. **fork()** 시 부모·자식 프로세스가 같은 물리 페이지 공유  
2. 둘 중 한쪽이 해당 페이지를 **쓰기** 요청하면  
3. OS가 **해당 페이지 복사** 후, 복사본에 쓰기 → 나머지는 여전히 공유  
- **장점**: 쓰기 전까지 메모리 절약, 프로세스 생성 비용 절감  

### 5.3 컨테이너(Docker) 환경에서 가상 메모리 할당  
- **cgroup**으로 컨테이너별 메모리 한도 설정 가능 (`memory.limit_in_bytes`)  
- **스왑 사용량** 제한 (`memory.memsw.limit_in_bytes`)  
- 컨테이너 내부에서 보이는 가용 메모리 ≠ 호스트 전체 메모리 → 리소스 격리  

### 5.4 실제 서비스에서 스왑이 잦아졌을 때 모니터링 지표와 대응 방안  
- **모니터링 지표**  
  - `vmstat`의 swap in/out rate, `iostat`의 iowait  
  - 프로세스별 페이지 폴트 수 (`/proc/<pid>/stat`)  
  - CPU 사용률 vs idle/steal 시간  
- **대응 방안**  
  - **메모리 증설** 또는 컨테이너 메모리 한도 상향  
  - **애플리케이션 레이어 캐시** 추가 (Redis, Memcached)  
  - **GC 튜닝**: young/old generation 비율 조정, GC 알고리즘 변경  
  - **데이터 구조 재설계**: 메모리 워킹 셋 축소, 불필요한 객체 제거  

---
